{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e53909a-d82d-418b-9eb6-8d2884d67e85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from reviewsdataset import loadBatchListwise, getReviews\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23405d44-9a2e-4bc9-991b-d203f96edeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = getReviews()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da8d647-40fb-428e-bc16-d20f71badd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.concat([pd.DataFrame(loadBatchListwise(r, i)) for i, r in enumerate(reviews[:700])]).reset_index(drop=True)\n",
    "valdf = pd.concat([pd.DataFrame(loadBatchListwise(r, i)) for i, r in enumerate(reviews[700:900])]).reset_index(drop=True)\n",
    "testdf = pd.concat([pd.DataFrame(loadBatchListwise(r, i)) for i, r in enumerate(reviews[900:1000])]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c12c16-162f-4576-bfbf-fd701f626614",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    10740\n",
       "1     3555\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebb60dc-e8aa-45d7-8566-bd2bd07b6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "traindf['positions'] = scaler.fit_transform(traindf[['positions']])\n",
    "valdf['positions'] = scaler.fit_transform(valdf[['positions']])\n",
    "testdf['positions'] = scaler.fit_transform(testdf[['positions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df7ccf7-2194-43f7-b72d-948a4faf7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    # Tokenize the sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the mean of the last hidden state as the sentence embedding\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze(0)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Example: Add embeddings to your dataset\n",
    "traindf['sentence_embedding'] = traindf['sentences'].apply(get_sentence_embedding)\n",
    "valdf['sentence_embedding'] = valdf['sentences'].apply(get_sentence_embedding)\n",
    "testdf['sentence_embedding'] = testdf['sentences'].apply(get_sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a6d689-aba3-4f97-86c7-d57b33110f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = np.array(traindf['sentence_embedding'].to_list())\n",
    "val_embeddings = np.array(valdf['sentence_embedding'].to_list())\n",
    "test_embeddings = np.array(testdf['sentence_embedding'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49b3a3bf-7cf0-42b1-a860-b7d500f8bef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14295, 768)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46058317-4689-45a2-aee9-e1dfc6b27b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensions (e.g., from 768 to 128)\n",
    "pca = PCA(n_components=128)\n",
    "reduced_train_embeddings = pca.fit_transform(train_embeddings)\n",
    "reduced_val_embeddings = pca.transform(val_embeddings)\n",
    "reduced_test_embeddings = pca.transform(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb445cbf-da4b-40f5-81a6-f26595018eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14295, 128)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dba98945-6356-474e-8ebb-c7e704a4184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of reduced embeddings to a DataFrame\n",
    "embeddings_df_train = pd.DataFrame(reduced_train_embeddings, index=traindf.index)\n",
    "embeddings_df_val = pd.DataFrame(reduced_val_embeddings, index=valdf.index)\n",
    "embeddings_df_test = pd.DataFrame(reduced_test_embeddings, index=testdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6dae30f-f2f3-4963-bb13-2c52ac825b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the reduced embeddings with the original DataFrame\n",
    "traindf = pd.concat([traindf, embeddings_df_train], axis=1)\n",
    "valdf = pd.concat([valdf, embeddings_df_val], axis=1)\n",
    "testdf = pd.concat([testdf, embeddings_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95021d85-b0c6-4211-8251-072e0fb7af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features\n",
    "feature_columns = embeddings_df_train.columns.tolist() + ['positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d330eb8-ef3f-4c7e-9c82-10f75afaf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    traindf[feature_columns],\n",
    "    label=traindf['labels'],\n",
    "    group=[len(traindf[traindf['reviewid'] == g]) for g in traindf['reviewid'].unique()]\n",
    ")\n",
    "\n",
    "val_data = lgb.Dataset(\n",
    "    valdf[feature_columns],\n",
    "    label=valdf['labels'],\n",
    "    group=[len(valdf[valdf['reviewid'] == g]) for g in valdf['reviewid'].unique()],\n",
    "    reference=train_data\n",
    ")\n",
    "\n",
    "test_data = lgb.Dataset(\n",
    "    testdf[feature_columns],\n",
    "    label=testdf['labels'],\n",
    "    group=[len(testdf[testdf['reviewid'] == g]) for g in testdf['reviewid'].unique()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa8e924f-80e6-4253-b640-e939837b3efe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32759\n",
      "[LightGBM] [Info] Number of data points in the train set: 14295, number of used features: 129\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[5]\tValid's ndcg@1: 0.64\tValid's ndcg@3: 0.697507\tValid's ndcg@5: 0.733924\n",
      "[10]\tValid's ndcg@1: 0.66\tValid's ndcg@3: 0.700722\tValid's ndcg@5: 0.740435\n",
      "[15]\tValid's ndcg@1: 0.68\tValid's ndcg@3: 0.718738\tValid's ndcg@5: 0.750822\n",
      "[20]\tValid's ndcg@1: 0.655\tValid's ndcg@3: 0.717981\tValid's ndcg@5: 0.75047\n",
      "[25]\tValid's ndcg@1: 0.655\tValid's ndcg@3: 0.711219\tValid's ndcg@5: 0.746746\n",
      "[30]\tValid's ndcg@1: 0.66\tValid's ndcg@3: 0.717879\tValid's ndcg@5: 0.751974\n",
      "[35]\tValid's ndcg@1: 0.665\tValid's ndcg@3: 0.714678\tValid's ndcg@5: 0.760217\n",
      "[40]\tValid's ndcg@1: 0.66\tValid's ndcg@3: 0.716818\tValid's ndcg@5: 0.75833\n",
      "[45]\tValid's ndcg@1: 0.675\tValid's ndcg@3: 0.725018\tValid's ndcg@5: 0.764246\n",
      "[50]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.73695\tValid's ndcg@5: 0.771127\n",
      "[55]\tValid's ndcg@1: 0.695\tValid's ndcg@3: 0.733713\tValid's ndcg@5: 0.766528\n",
      "[60]\tValid's ndcg@1: 0.69\tValid's ndcg@3: 0.736055\tValid's ndcg@5: 0.76798\n",
      "[65]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.743154\tValid's ndcg@5: 0.773656\n",
      "[70]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.747767\tValid's ndcg@5: 0.778914\n",
      "[75]\tValid's ndcg@1: 0.685\tValid's ndcg@3: 0.733869\tValid's ndcg@5: 0.77469\n",
      "[80]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.740556\tValid's ndcg@5: 0.779675\n",
      "[85]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.747291\tValid's ndcg@5: 0.782511\n",
      "[90]\tValid's ndcg@1: 0.71\tValid's ndcg@3: 0.743944\tValid's ndcg@5: 0.780179\n",
      "[95]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.746462\tValid's ndcg@5: 0.778806\n",
      "[100]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.744618\tValid's ndcg@5: 0.781133\n",
      "[105]\tValid's ndcg@1: 0.705\tValid's ndcg@3: 0.743333\tValid's ndcg@5: 0.782026\n",
      "[110]\tValid's ndcg@1: 0.705\tValid's ndcg@3: 0.742832\tValid's ndcg@5: 0.78212\n",
      "[115]\tValid's ndcg@1: 0.71\tValid's ndcg@3: 0.749688\tValid's ndcg@5: 0.783516\n",
      "[120]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.747806\tValid's ndcg@5: 0.783666\n",
      "[125]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.74698\tValid's ndcg@5: 0.783815\n",
      "[130]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.750448\tValid's ndcg@5: 0.786642\n",
      "[135]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.754657\tValid's ndcg@5: 0.788856\n",
      "[140]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.755198\tValid's ndcg@5: 0.787505\n",
      "[145]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.754891\tValid's ndcg@5: 0.787836\n",
      "[150]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.754276\tValid's ndcg@5: 0.788416\n",
      "[155]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.753715\tValid's ndcg@5: 0.788003\n",
      "[160]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.751871\tValid's ndcg@5: 0.787022\n",
      "[165]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.753014\tValid's ndcg@5: 0.788948\n",
      "[170]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.751996\tValid's ndcg@5: 0.789288\n",
      "[175]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.755416\tValid's ndcg@5: 0.790589\n",
      "[180]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.754596\tValid's ndcg@5: 0.789351\n",
      "[185]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.755977\tValid's ndcg@5: 0.790149\n",
      "[190]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.756843\tValid's ndcg@5: 0.790542\n",
      "[195]\tValid's ndcg@1: 0.735\tValid's ndcg@3: 0.755268\tValid's ndcg@5: 0.791447\n",
      "[200]\tValid's ndcg@1: 0.74\tValid's ndcg@3: 0.762113\tValid's ndcg@5: 0.79253\n",
      "[205]\tValid's ndcg@1: 0.74\tValid's ndcg@3: 0.758594\tValid's ndcg@5: 0.792312\n",
      "[210]\tValid's ndcg@1: 0.745\tValid's ndcg@3: 0.761417\tValid's ndcg@5: 0.793924\n",
      "[215]\tValid's ndcg@1: 0.745\tValid's ndcg@3: 0.762124\tValid's ndcg@5: 0.794451\n",
      "[220]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.760729\tValid's ndcg@5: 0.792982\n",
      "[225]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.763377\tValid's ndcg@5: 0.795445\n",
      "[230]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.76186\tValid's ndcg@5: 0.792299\n",
      "[235]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.763648\tValid's ndcg@5: 0.794802\n",
      "[240]\tValid's ndcg@1: 0.735\tValid's ndcg@3: 0.764514\tValid's ndcg@5: 0.795491\n",
      "[245]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.763341\tValid's ndcg@5: 0.793445\n",
      "[250]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.764514\tValid's ndcg@5: 0.794633\n",
      "[255]\tValid's ndcg@1: 0.74\tValid's ndcg@3: 0.765493\tValid's ndcg@5: 0.797158\n",
      "[260]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.765229\tValid's ndcg@5: 0.793875\n",
      "[265]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.764573\tValid's ndcg@5: 0.793401\n",
      "[270]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.765884\tValid's ndcg@5: 0.796245\n",
      "[275]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.764056\tValid's ndcg@5: 0.791964\n",
      "[280]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.760635\tValid's ndcg@5: 0.792761\n",
      "[285]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.764657\tValid's ndcg@5: 0.793415\n",
      "[290]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.764962\tValid's ndcg@5: 0.794778\n",
      "[295]\tValid's ndcg@1: 0.735\tValid's ndcg@3: 0.769348\tValid's ndcg@5: 0.794525\n",
      "[300]\tValid's ndcg@1: 0.73\tValid's ndcg@3: 0.766654\tValid's ndcg@5: 0.794363\n",
      "[305]\tValid's ndcg@1: 0.735\tValid's ndcg@3: 0.769348\tValid's ndcg@5: 0.797273\n",
      "Early stopping, best iteration is:\n",
      "[209]\tValid's ndcg@1: 0.745\tValid's ndcg@3: 0.762072\tValid's ndcg@5: 0.795486\n",
      "Best iteration: 209\n"
     ]
    }
   ],
   "source": [
    "# Train the model using LambdaRank objective\n",
    "params = {\n",
    "    'objective': 'lambdarank',  # Listwise ranking\n",
    "    # 'metric': 'auc',  # Evaluation metric for ranking\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [1, 3, 5],  # NDCG evaluation at different ranks\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.03,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 21\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_set=train_data,\n",
    "    valid_sets=[val_data],\n",
    "    valid_names=['Valid'],\n",
    "    num_boost_round=500,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100), \n",
    "        lgb.log_evaluation(5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# After training, the best iteration (round) can be accessed\n",
    "best_iteration = model.best_iteration\n",
    "print(f\"Best iteration: {best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5721b9bf-2782-4478-b9cc-d6bec96d7d6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7438826287974009\n"
     ]
    }
   ],
   "source": [
    "# Predict scores for test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "test_scores = model.predict(testdf[feature_columns], num_iteration=best_iteration)\n",
    "\n",
    "auc = roc_auc_score(testdf['labels'], test_scores)\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "# Add scores to test dataframe and sort sentences within each group\n",
    "testdf['score'] = test_scores\n",
    "testdf = testdf.sort_values(by=['reviewid', 'score'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e93682c-cf87-4f19-92d1-2f10fd8d248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(scores):\n",
    "    return 1 / (1 + np.exp(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a03671d-c12d-4e3b-9ab9-83fd290d02af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Calculating accuracy\n",
    "predictions = []\n",
    "truths = []\n",
    "threshold=0.7\n",
    "for i in range(100):\n",
    "    probabs = get_probabilities(np.array(testdf[testdf['reviewid']==i]['score']))\n",
    "    truths.extend(testdf[testdf['reviewid']==i]['labels'].tolist())\n",
    "    preds = [1 if p>threshold else 0 for p in probabs]\n",
    "    predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c7600aa-80d0-4a4e-a10e-e44d8694fdc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284848484848485"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6b45b0d-592b-4070-a7aa-1b39f23f3c24",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['reviewid', 'sentences', 'positions', 'score', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47310144-b6a4-4275-9d83-4f60a2451303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>sentences</th>\n",
       "      <th>positions</th>\n",
       "      <th>score</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6</td>\n",
       "      <td>she'd been fucking his cousin how did this see...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.910226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6</td>\n",
       "      <td>I mean the author played it off but that's...H...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.635168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6</td>\n",
       "      <td>Kinda?</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.130233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6</td>\n",
       "      <td>the author tried to play it off like she thoug...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.017601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>but there was zero consent, in fact there was ...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>-0.061886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>Number two so...sexual assault is a grand basi...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>-0.077634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6</td>\n",
       "      <td>Ish?</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>-0.587823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6</td>\n",
       "      <td>I've almost talked myself into lower stars the...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.786535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6</td>\n",
       "      <td>number one - JUST SAY NO TO INSTALOVE.</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>-1.782185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>I enjoyed a lot about this book but it tanked ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.845245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reviewid                                          sentences  positions  \\\n",
       "52         6  she'd been fucking his cousin how did this see...   0.044444   \n",
       "51         6  I mean the author played it off but that's...H...   0.033333   \n",
       "54         6                                             Kinda?   0.066667   \n",
       "53         6  the author tried to play it off like she thoug...   0.055556   \n",
       "56         6  but there was zero consent, in fact there was ...   0.088889   \n",
       "50         6  Number two so...sexual assault is a grand basi...   0.022222   \n",
       "55         6                                               Ish?   0.077778   \n",
       "57         6  I've almost talked myself into lower stars the...   0.100000   \n",
       "49         6             number one - JUST SAY NO TO INSTALOVE.   0.011111   \n",
       "48         6  I enjoyed a lot about this book but it tanked ...   0.000000   \n",
       "\n",
       "       score  labels  \n",
       "52  0.910226       1  \n",
       "51  0.635168       1  \n",
       "54  0.130233       1  \n",
       "53 -0.017601       1  \n",
       "56 -0.061886       1  \n",
       "50 -0.077634       1  \n",
       "55 -0.587823       1  \n",
       "57 -0.786535       0  \n",
       "49 -1.782185       0  \n",
       "48 -3.845245       0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[testdf['reviewid']==6][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c5d70c4-8ffc-49d4-beb3-91f899d3b14a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from reviewplot import print_with_probs\n",
    "\n",
    "testdf = testdf.sort_values(by=['reviewid', 'positions'], ascending=[True, True])\n",
    "\n",
    "probabilities = get_probabilities(np.array(testdf[testdf['reviewid']==5]['score']))\n",
    "truth = np.array(testdf[testdf['reviewid']==5]['labels']).astype(float)\n",
    "sentences = np.array(testdf[testdf['reviewid']==5]['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2632d23-7f28-4eba-b0c1-dcf8f60d373a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">this was far from perfect but I still enjoyed it. I was snickering a little at the lack of sex scenes because, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">well, I've read foster before.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e2f3f3\"> But I think it was better not to write them if she couldn't write them well.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #76aed1\"> It was </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #76aed1\">a short, sweet romance with interfering family.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\"> it doesn't surprise me that when the girls are basically like </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\">\"fix </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\">this\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\">, it didn't even occur to the guys to go to Chris and say </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\">\"you can tell Matt\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\">.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\"> No, their wives said </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\">\"fix it\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\"> </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\">so THEY went and told Matt and invited him over to talk to Chris so they could HOVER.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e2f3f3\"> NGL, I was incredibly amused </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #e2f3f3\">by it.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;0;0;0;48;2;69;118;180mthis was far from perfect but I still enjoyed it.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m I was snickering a little at the lack of sex scenes because, \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;69;118;180mwell, I've read foster before.\u001b[0m\u001b[38;2;0;0;0;48;2;226;243;243m But I think it was better not to write them if she couldn't write them well.\u001b[0m\u001b[38;2;0;0;0;48;2;118;174;209m It was \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;118;174;209ma short, sweet romance with interfering family.\u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m it doesn't surprise me that when the girls are basically like \u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m\"fix \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;253;218;138mthis\"\u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m, it didn't even occur to the guys to go to Chris and say \u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m\"you can tell Matt\"\u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m.\u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m No, their wives said \u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m\"fix it\"\u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;251;165;92mso THEY went and told Matt and invited him over to talk to Chris so they could HOVER.\u001b[0m\u001b[38;2;0;0;0;48;2;226;243;243m NGL, I was incredibly amused \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;226;243;243mby it.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_with_probs(sentences, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a7a5e7e-32c3-45c4-a0c0-f8d3f7571225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">this was far from perfect but I still enjoyed it. I was snickering a little at the lack of sex scenes because, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">well, I've read foster before. But I think it was better not to write them if she couldn't write them well. It was </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">a short, sweet romance with interfering family.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\"> it doesn't surprise me that when the girls are basically like </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">\"fix </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">this\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">, it didn't even occur to the guys to go to Chris and say </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">\"you can tell Matt\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">. No, their wives said </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">\"fix it\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\"> </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">so THEY went and told Matt and invited him over to talk to Chris so they could HOVER.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\"> NGL, I was incredibly amused </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">by it.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;0;0;0;48;2;69;118;180mthis was far from perfect but I still enjoyed it.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m I was snickering a little at the lack of sex scenes because, \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;69;118;180mwell, I've read foster before.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m But I think it was better not to write them if she couldn't write them well.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m It was \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;69;118;180ma short, sweet romance with interfering family.\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m it doesn't surprise me that when the girls are basically like \u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m\"fix \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;204;37;38mthis\"\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m, it didn't even occur to the guys to go to Chris and say \u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m\"you can tell Matt\"\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m.\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m No, their wives said \u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m\"fix it\"\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;204;37;38mso THEY went and told Matt and invited him over to talk to Chris so they could HOVER.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m NGL, I was incredibly amused \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;69;118;180mby it.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_with_probs(sentences, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e771449-354c-4891-af33-41c85f5d1ced",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
