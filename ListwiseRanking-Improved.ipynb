{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133d32f3-e741-4380-846b-50e3b505c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/anaykulkarni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/anaykulkarni/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from reviewsdataset import loadBatchListwise, getReviews\n",
    "from itemspecificity import getItemSpecificity\n",
    "from sklearn.decomposition import PCA\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46348b2f-ca76-4551-9d6a-c0f927ffded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = getReviews()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceab2004-376e-44ba-9b10-298a750a550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_freq, inv_item_freq = getItemSpecificity(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6eabc6-f024-4233-9f4c-d262e11dfec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "sw = stopwords.words('english')\n",
    "sp = string.punctuation\n",
    "\n",
    "def get_item_specificity(word, bookid):\n",
    "    return doc_freq[bookid][word] * inv_item_freq[word]\n",
    "\n",
    "def get_score_by_sentence_max(row):\n",
    "    text, bookid = row['sentences'], row['bookid']\n",
    "    words = [word for word in text.split() if word.lower() not in sw]\n",
    "    cleaned_words = [''.join([c for c in word if c not in sp]) for word in words if len(word)>1]\n",
    "    if len(cleaned_words) < 1:\n",
    "        return 0\n",
    "    score = np.max([get_item_specificity(w, bookid) for w in cleaned_words])\n",
    "    return score\n",
    "\n",
    "def get_score_by_sentence_mean(row):\n",
    "    text, bookid = row['sentences'], row['bookid']\n",
    "    words = [word for word in text.split() if word.lower() not in sw]\n",
    "    cleaned_words = [''.join([c for c in word if c not in sp]) for word in words if len(word)>1]\n",
    "    if len(cleaned_words) < 1:\n",
    "        return 0\n",
    "    score = np.mean([get_item_specificity(w, bookid) for w in cleaned_words])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166078a7-ca29-4eed-ad79-8887643106bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.concat([pd.DataFrame(loadBatchListwise(r, i)) for i, r in enumerate(reviews[:700])]).reset_index(drop=True)\n",
    "valdf = pd.concat([pd.DataFrame(loadBatchListwise(r, i)) for i, r in enumerate(reviews[700:900])]).reset_index(drop=True)\n",
    "testdf = pd.concat([pd.DataFrame(loadBatchListwise(r, i)) for i, r in enumerate(reviews[900:1000])]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed1de6c-be3d-4365-8110-2d803c6ca9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf['item_spec_score_max'] = traindf.apply(get_score_by_sentence_max, axis=1)\n",
    "valdf['item_spec_score_max'] = valdf.apply(get_score_by_sentence_max, axis=1)\n",
    "testdf['item_spec_score_max'] = testdf.apply(get_score_by_sentence_max, axis=1)\n",
    "traindf['item_spec_score_mean'] = traindf.apply(get_score_by_sentence_mean, axis=1)\n",
    "valdf['item_spec_score_mean'] = valdf.apply(get_score_by_sentence_mean, axis=1)\n",
    "testdf['item_spec_score_mean'] = testdf.apply(get_score_by_sentence_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fdb0dd6-6980-4e6b-a95c-dbc1f1e9c228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>positions</th>\n",
       "      <th>reviewid</th>\n",
       "      <th>bookid</th>\n",
       "      <th>item_spec_score_max</th>\n",
       "      <th>item_spec_score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a fun series.</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.013789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved Wool, and Dust and Shift both gave us ...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.027685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think the first book was by far the best, bu...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.026657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was the conclusion we wanted to see - the p...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.036474</td>\n",
       "      <td>0.021774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My problem with this book is there were lots o...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.036625</td>\n",
       "      <td>0.024668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14290</th>\n",
       "      <td>Will read the next.</td>\n",
       "      <td>Forever Odd</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>698</td>\n",
       "      <td>16433</td>\n",
       "      <td>0.177566</td>\n",
       "      <td>0.144543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>If I only had one word to sum it up then \"odd\".</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.122285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>It did keep swapping from first to third perso...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>0.104940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>Some dark things happen which kind of just get...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>0.086142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>Really odd, and the twist at the end, a little...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.116832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14295 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences         contexts  \\\n",
       "0                                     What a fun series.             Dust   \n",
       "1      I loved Wool, and Dust and Shift both gave us ...             Dust   \n",
       "2      I think the first book was by far the best, bu...             Dust   \n",
       "3      It was the conclusion we wanted to see - the p...             Dust   \n",
       "4      My problem with this book is there were lots o...             Dust   \n",
       "...                                                  ...              ...   \n",
       "14290                                Will read the next.      Forever Odd   \n",
       "14291    If I only had one word to sum it up then \"odd\".  The Lace Reader   \n",
       "14292  It did keep swapping from first to third perso...  The Lace Reader   \n",
       "14293  Some dark things happen which kind of just get...  The Lace Reader   \n",
       "14294  Really odd, and the twist at the end, a little...  The Lace Reader   \n",
       "\n",
       "       labels  positions  reviewid    bookid  item_spec_score_max  \\\n",
       "0           0          0         0  17855756             0.015290   \n",
       "1           0          1         0  17855756             0.050604   \n",
       "2           0          2         0  17855756             0.050604   \n",
       "3           1          3         0  17855756             0.036474   \n",
       "4           1          4         0  17855756             0.036625   \n",
       "...       ...        ...       ...       ...                  ...   \n",
       "14290       0          3       698     16433             0.177566   \n",
       "14291       0          0       699   1951125             0.215878   \n",
       "14292       1          1       699   1951125             0.143460   \n",
       "14293       0          2       699   1951125             0.119985   \n",
       "14294       0          3       699   1951125             0.215878   \n",
       "\n",
       "       item_spec_score_mean  \n",
       "0                  0.013789  \n",
       "1                  0.027685  \n",
       "2                  0.026657  \n",
       "3                  0.021774  \n",
       "4                  0.024668  \n",
       "...                     ...  \n",
       "14290              0.144543  \n",
       "14291              0.122285  \n",
       "14292              0.104940  \n",
       "14293              0.086142  \n",
       "14294              0.116832  \n",
       "\n",
       "[14295 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "583e8e2a-b2a6-4b0c-9502-3efaf7837125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',  # Remove common stopwords\n",
    "                                   ngram_range=(1, 1),\n",
    "                                   norm='l2',\n",
    "                                   lowercase=True,\n",
    "                                   use_idf=True,\n",
    "                                   smooth_idf=True)\n",
    "# traindf['tfidfscore'] = np.array(tfidf_vectorizer.fit_transform(traindf['sentences']).sum(axis=1))\n",
    "# valdf['tfidfscore'] = np.array(tfidf_vectorizer.transform(valdf['sentences']).sum(axis=1))\n",
    "# testdf['tfidfscore'] = np.array(tfidf_vectorizer.transform(testdf['sentences']).sum(axis=1))\n",
    "\n",
    "# Train data: Compute max TF-IDF score for each sentence\n",
    "traindf['tfidfscore'] = np.array(\n",
    "    tfidf_vectorizer.fit_transform(traindf['sentences']).max(axis=1).toarray()\n",
    ").flatten()\n",
    "\n",
    "# Validation data: Compute max TF-IDF score for each sentence\n",
    "valdf['tfidfscore'] = np.array(\n",
    "    tfidf_vectorizer.transform(valdf['sentences']).max(axis=1).toarray()\n",
    ").flatten()\n",
    "\n",
    "# Test data: Compute max TF-IDF score for each sentence\n",
    "testdf['tfidfscore'] = np.array(\n",
    "    tfidf_vectorizer.transform(testdf['sentences']).max(axis=1).toarray()\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d9e2c5f-07a8-4ee3-9517-d86bfd76f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "traindf['positions'] = scaler.fit_transform(traindf[['positions']])\n",
    "valdf['positions'] = scaler.fit_transform(valdf[['positions']])\n",
    "testdf['positions'] = scaler.fit_transform(testdf[['positions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93dcbb1b-8ba6-4ecd-a50e-51700b34239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_combined_embedding(row):\n",
    "    # Combine the 'sentence' and 'context' columns\n",
    "    # combined_text = f\"{row['sentences']}\" # [SEP] {row['contexts']}\"\n",
    "    # Tokenize the combined text\n",
    "    inputs = tokenizer(row['sentences'], return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    # Pass through the BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the pooler_output (CLS token embedding) as the sentence embedding\n",
    "    # embedding = outputs.pooler_output.squeeze(0)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze(0)\n",
    "    return embedding.numpy()\n",
    "\n",
    "# Apply the function to calculate embeddings\n",
    "traindf['combined_embedding'] = traindf.apply(get_combined_embedding, axis=1)\n",
    "valdf['combined_embedding'] = valdf.apply(get_combined_embedding, axis=1)\n",
    "testdf['combined_embedding'] = testdf.apply(get_combined_embedding, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d92ad9d-8db0-4912-b2e4-b64fc585b44b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_embeddings = np.array(traindf['combined_embedding'].to_list())\n",
    "val_embeddings = np.array(valdf['combined_embedding'].to_list())\n",
    "test_embeddings = np.array(testdf['combined_embedding'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab93b243-9322-4807-af1c-f981dcab799f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14295, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "386cd7ac-343c-4906-b03c-e60966450d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensions (e.g., from 768 to 128)\n",
    "pca = PCA(n_components=128)\n",
    "reduced_train_embeddings = pca.fit_transform(train_embeddings)\n",
    "reduced_val_embeddings = pca.transform(val_embeddings)\n",
    "reduced_test_embeddings = pca.transform(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7accdbe-ed46-40d5-b7d4-63e5d6e323aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14295, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60c5c7f1-00ac-40e2-a261-0e2ce03743ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of reduced embeddings to a DataFrame\n",
    "embeddings_df_train = pd.DataFrame(reduced_train_embeddings, index=traindf.index)\n",
    "embeddings_df_val = pd.DataFrame(reduced_val_embeddings, index=valdf.index)\n",
    "embeddings_df_test = pd.DataFrame(reduced_test_embeddings, index=testdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00dc54ad-663d-496b-b69c-e30c2ceb2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep = ['sentences', 'contexts', 'labels', 'positions', 'reviewid', 'tfidfscore', 'combined_embedding']\n",
    "# traindf = traindf[keep]\n",
    "# valdf = valdf[keep]\n",
    "# testdf = testdf[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ff58810-d1f7-4026-a476-de35289576bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the reduced embeddings with the original DataFrame\n",
    "traindf = pd.concat([traindf, embeddings_df_train], axis=1)\n",
    "valdf = pd.concat([valdf, embeddings_df_val], axis=1)\n",
    "testdf = pd.concat([testdf, embeddings_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d5f2626-49a5-4f52-9471-23e2649bd658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>positions</th>\n",
       "      <th>reviewid</th>\n",
       "      <th>bookid</th>\n",
       "      <th>item_spec_score_max</th>\n",
       "      <th>item_spec_score_mean</th>\n",
       "      <th>tfidfscore</th>\n",
       "      <th>combined_embedding</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a fun series.</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>0.785133</td>\n",
       "      <td>[0.13568804, -0.42419568, 0.22611226, 0.193501...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435559</td>\n",
       "      <td>-0.028487</td>\n",
       "      <td>0.224099</td>\n",
       "      <td>0.136431</td>\n",
       "      <td>0.306240</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>0.344808</td>\n",
       "      <td>0.247321</td>\n",
       "      <td>0.494328</td>\n",
       "      <td>-0.217180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved Wool, and Dust and Shift both gave us ...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.027685</td>\n",
       "      <td>0.417833</td>\n",
       "      <td>[0.27358928, 0.051419273, 0.13299458, 0.160809...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.457130</td>\n",
       "      <td>-0.071240</td>\n",
       "      <td>0.153160</td>\n",
       "      <td>-0.042372</td>\n",
       "      <td>0.042692</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.195423</td>\n",
       "      <td>0.173676</td>\n",
       "      <td>0.141578</td>\n",
       "      <td>-0.039212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think the first book was by far the best, bu...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>0.484192</td>\n",
       "      <td>[-0.07830019, -0.3241384, 0.26186368, -0.03014...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182080</td>\n",
       "      <td>0.103592</td>\n",
       "      <td>0.182030</td>\n",
       "      <td>0.297668</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>0.086083</td>\n",
       "      <td>-0.020139</td>\n",
       "      <td>0.024291</td>\n",
       "      <td>-0.069403</td>\n",
       "      <td>-0.231655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was the conclusion we wanted to see - the p...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.036474</td>\n",
       "      <td>0.021774</td>\n",
       "      <td>0.535509</td>\n",
       "      <td>[0.2418055, -0.1830729, 0.39519662, -0.0359889...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044703</td>\n",
       "      <td>-0.406086</td>\n",
       "      <td>0.235105</td>\n",
       "      <td>-0.193855</td>\n",
       "      <td>0.113906</td>\n",
       "      <td>-0.282803</td>\n",
       "      <td>0.419765</td>\n",
       "      <td>0.222623</td>\n",
       "      <td>-0.139149</td>\n",
       "      <td>-0.090754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My problem with this book is there were lots o...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.036625</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>0.653747</td>\n",
       "      <td>[0.096865825, 0.07542943, 0.061335944, 0.11228...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320965</td>\n",
       "      <td>-0.098903</td>\n",
       "      <td>0.168757</td>\n",
       "      <td>0.058654</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>-0.019319</td>\n",
       "      <td>-0.196473</td>\n",
       "      <td>0.120615</td>\n",
       "      <td>-0.143962</td>\n",
       "      <td>0.279851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14290</th>\n",
       "      <td>Will read the next.</td>\n",
       "      <td>Forever Odd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>698</td>\n",
       "      <td>16433</td>\n",
       "      <td>0.177566</td>\n",
       "      <td>0.144543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.10743135, -0.3015935, 0.03974713, 0.0797066...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358973</td>\n",
       "      <td>-0.126794</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.094335</td>\n",
       "      <td>0.336781</td>\n",
       "      <td>0.012558</td>\n",
       "      <td>-0.012272</td>\n",
       "      <td>0.594620</td>\n",
       "      <td>-0.238397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>If I only had one word to sum it up then \"odd\".</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.122285</td>\n",
       "      <td>0.631535</td>\n",
       "      <td>[0.12413848, 0.19855367, 0.042200167, 0.019212...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060622</td>\n",
       "      <td>-0.015157</td>\n",
       "      <td>-0.239266</td>\n",
       "      <td>-0.518556</td>\n",
       "      <td>0.096743</td>\n",
       "      <td>-0.104593</td>\n",
       "      <td>0.085093</td>\n",
       "      <td>0.047637</td>\n",
       "      <td>0.067509</td>\n",
       "      <td>0.148426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>It did keep swapping from first to third perso...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>0.104940</td>\n",
       "      <td>0.356158</td>\n",
       "      <td>[-0.15070404, 0.08648281, 0.079170436, 0.15373...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363667</td>\n",
       "      <td>0.361313</td>\n",
       "      <td>-0.013605</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>-0.074386</td>\n",
       "      <td>0.271997</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>0.021483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>Some dark things happen which kind of just get...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>0.086142</td>\n",
       "      <td>0.528640</td>\n",
       "      <td>[0.5452099, 0.20342357, 0.3213288, 0.1988398, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199145</td>\n",
       "      <td>-0.415404</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>-0.126928</td>\n",
       "      <td>0.120654</td>\n",
       "      <td>0.226310</td>\n",
       "      <td>0.314678</td>\n",
       "      <td>0.093227</td>\n",
       "      <td>-0.403474</td>\n",
       "      <td>0.314984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>Really odd, and the twist at the end, a little...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.116832</td>\n",
       "      <td>0.530047</td>\n",
       "      <td>[-0.10798588, -0.28911787, 0.14432462, 0.18672...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053777</td>\n",
       "      <td>-0.305939</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.384679</td>\n",
       "      <td>0.347311</td>\n",
       "      <td>-0.136916</td>\n",
       "      <td>-0.066333</td>\n",
       "      <td>-0.024981</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>-0.263914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14295 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences         contexts  \\\n",
       "0                                     What a fun series.             Dust   \n",
       "1      I loved Wool, and Dust and Shift both gave us ...             Dust   \n",
       "2      I think the first book was by far the best, bu...             Dust   \n",
       "3      It was the conclusion we wanted to see - the p...             Dust   \n",
       "4      My problem with this book is there were lots o...             Dust   \n",
       "...                                                  ...              ...   \n",
       "14290                                Will read the next.      Forever Odd   \n",
       "14291    If I only had one word to sum it up then \"odd\".  The Lace Reader   \n",
       "14292  It did keep swapping from first to third perso...  The Lace Reader   \n",
       "14293  Some dark things happen which kind of just get...  The Lace Reader   \n",
       "14294  Really odd, and the twist at the end, a little...  The Lace Reader   \n",
       "\n",
       "       labels  positions  reviewid    bookid  item_spec_score_max  \\\n",
       "0           0   0.000000         0  17855756             0.015290   \n",
       "1           0   0.007143         0  17855756             0.050604   \n",
       "2           0   0.014286         0  17855756             0.050604   \n",
       "3           1   0.021429         0  17855756             0.036474   \n",
       "4           1   0.028571         0  17855756             0.036625   \n",
       "...       ...        ...       ...       ...                  ...   \n",
       "14290       0   0.021429       698     16433             0.177566   \n",
       "14291       0   0.000000       699   1951125             0.215878   \n",
       "14292       1   0.007143       699   1951125             0.143460   \n",
       "14293       0   0.014286       699   1951125             0.119985   \n",
       "14294       0   0.021429       699   1951125             0.215878   \n",
       "\n",
       "       item_spec_score_mean  tfidfscore  \\\n",
       "0                  0.013789    0.785133   \n",
       "1                  0.027685    0.417833   \n",
       "2                  0.026657    0.484192   \n",
       "3                  0.021774    0.535509   \n",
       "4                  0.024668    0.653747   \n",
       "...                     ...         ...   \n",
       "14290              0.144543    1.000000   \n",
       "14291              0.122285    0.631535   \n",
       "14292              0.104940    0.356158   \n",
       "14293              0.086142    0.528640   \n",
       "14294              0.116832    0.530047   \n",
       "\n",
       "                                      combined_embedding  ...       118  \\\n",
       "0      [0.13568804, -0.42419568, 0.22611226, 0.193501...  ... -0.435559   \n",
       "1      [0.27358928, 0.051419273, 0.13299458, 0.160809...  ... -0.457130   \n",
       "2      [-0.07830019, -0.3241384, 0.26186368, -0.03014...  ... -0.182080   \n",
       "3      [0.2418055, -0.1830729, 0.39519662, -0.0359889...  ... -0.044703   \n",
       "4      [0.096865825, 0.07542943, 0.061335944, 0.11228...  ...  0.320965   \n",
       "...                                                  ...  ...       ...   \n",
       "14290  [0.10743135, -0.3015935, 0.03974713, 0.0797066...  ...  0.358973   \n",
       "14291  [0.12413848, 0.19855367, 0.042200167, 0.019212...  ... -0.060622   \n",
       "14292  [-0.15070404, 0.08648281, 0.079170436, 0.15373...  ... -0.363667   \n",
       "14293  [0.5452099, 0.20342357, 0.3213288, 0.1988398, ...  ... -0.199145   \n",
       "14294  [-0.10798588, -0.28911787, 0.14432462, 0.18672...  ...  0.053777   \n",
       "\n",
       "            119       120       121       122       123       124       125  \\\n",
       "0     -0.028487  0.224099  0.136431  0.306240  0.047697  0.344808  0.247321   \n",
       "1     -0.071240  0.153160 -0.042372  0.042692  0.019526  0.195423  0.173676   \n",
       "2      0.103592  0.182030  0.297668 -0.002652  0.086083 -0.020139  0.024291   \n",
       "3     -0.406086  0.235105 -0.193855  0.113906 -0.282803  0.419765  0.222623   \n",
       "4     -0.098903  0.168757  0.058654  0.006225 -0.019319 -0.196473  0.120615   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14290 -0.126794  0.024562  0.004872  0.094335  0.336781  0.012558 -0.012272   \n",
       "14291 -0.015157 -0.239266 -0.518556  0.096743 -0.104593  0.085093  0.047637   \n",
       "14292  0.361313 -0.013605  0.017482  0.059031  0.003847 -0.074386  0.271997   \n",
       "14293 -0.415404  0.013450 -0.126928  0.120654  0.226310  0.314678  0.093227   \n",
       "14294 -0.305939 -0.016809 -0.384679  0.347311 -0.136916 -0.066333 -0.024981   \n",
       "\n",
       "            126       127  \n",
       "0      0.494328 -0.217180  \n",
       "1      0.141578 -0.039212  \n",
       "2     -0.069403 -0.231655  \n",
       "3     -0.139149 -0.090754  \n",
       "4     -0.143962  0.279851  \n",
       "...         ...       ...  \n",
       "14290  0.594620 -0.238397  \n",
       "14291  0.067509  0.148426  \n",
       "14292 -0.012426  0.021483  \n",
       "14293 -0.403474  0.314984  \n",
       "14294  0.198668 -0.263914  \n",
       "\n",
       "[14295 rows x 138 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a4c9871-f522-41ef-a0d3-a147b0db8e00",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the features\n",
    "feature_columns = embeddings_df_train.columns.tolist() + ['item_spec_score_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3301b45a-78e2-4cb2-bc4a-0245117eae6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(\n",
    "    traindf[feature_columns],\n",
    "    label=traindf['labels'],\n",
    "    group=[len(traindf[traindf['reviewid'] == g]) for g in traindf['reviewid'].unique()]\n",
    ")\n",
    "\n",
    "val_data = lgb.Dataset(\n",
    "    valdf[feature_columns],\n",
    "    label=valdf['labels'],\n",
    "    group=[len(valdf[valdf['reviewid'] == g]) for g in valdf['reviewid'].unique()],\n",
    "    reference=train_data\n",
    ")\n",
    "\n",
    "test_data = lgb.Dataset(\n",
    "    testdf[feature_columns],\n",
    "    label=testdf['labels'],\n",
    "    group=[len(testdf[testdf['reviewid'] == g]) for g in testdf['reviewid'].unique()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba7f3c28-0db8-468f-bbb4-1fb11e725ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32895\n",
      "[LightGBM] [Info] Number of data points in the train set: 14295, number of used features: 129\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[5]\tValid's ndcg@1: 0.645\tValid's ndcg@3: 0.678318\tValid's ndcg@5: 0.710181\n",
      "[10]\tValid's ndcg@1: 0.65\tValid's ndcg@3: 0.689993\tValid's ndcg@5: 0.721997\n",
      "[15]\tValid's ndcg@1: 0.68\tValid's ndcg@3: 0.716226\tValid's ndcg@5: 0.740223\n",
      "[20]\tValid's ndcg@1: 0.65\tValid's ndcg@3: 0.710019\tValid's ndcg@5: 0.733967\n",
      "[25]\tValid's ndcg@1: 0.665\tValid's ndcg@3: 0.719555\tValid's ndcg@5: 0.742407\n",
      "[30]\tValid's ndcg@1: 0.65\tValid's ndcg@3: 0.723198\tValid's ndcg@5: 0.743447\n",
      "[35]\tValid's ndcg@1: 0.66\tValid's ndcg@3: 0.721084\tValid's ndcg@5: 0.743863\n",
      "[40]\tValid's ndcg@1: 0.67\tValid's ndcg@3: 0.726072\tValid's ndcg@5: 0.744673\n",
      "[45]\tValid's ndcg@1: 0.685\tValid's ndcg@3: 0.725756\tValid's ndcg@5: 0.752608\n",
      "[50]\tValid's ndcg@1: 0.685\tValid's ndcg@3: 0.7244\tValid's ndcg@5: 0.75116\n",
      "[55]\tValid's ndcg@1: 0.69\tValid's ndcg@3: 0.726345\tValid's ndcg@5: 0.75477\n",
      "[60]\tValid's ndcg@1: 0.69\tValid's ndcg@3: 0.723489\tValid's ndcg@5: 0.753538\n",
      "[65]\tValid's ndcg@1: 0.69\tValid's ndcg@3: 0.733348\tValid's ndcg@5: 0.757422\n",
      "[70]\tValid's ndcg@1: 0.68\tValid's ndcg@3: 0.728539\tValid's ndcg@5: 0.75582\n",
      "[75]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.735172\tValid's ndcg@5: 0.764227\n",
      "[80]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.744199\tValid's ndcg@5: 0.765725\n",
      "[85]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.738449\tValid's ndcg@5: 0.763561\n",
      "[90]\tValid's ndcg@1: 0.695\tValid's ndcg@3: 0.734028\tValid's ndcg@5: 0.7635\n",
      "[95]\tValid's ndcg@1: 0.69\tValid's ndcg@3: 0.737378\tValid's ndcg@5: 0.7688\n",
      "[100]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.743272\tValid's ndcg@5: 0.774357\n",
      "[105]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.744468\tValid's ndcg@5: 0.777944\n",
      "[110]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.740448\tValid's ndcg@5: 0.775875\n",
      "[115]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.743808\tValid's ndcg@5: 0.777929\n",
      "[120]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.740983\tValid's ndcg@5: 0.777074\n",
      "[125]\tValid's ndcg@1: 0.71\tValid's ndcg@3: 0.735723\tValid's ndcg@5: 0.773908\n",
      "[130]\tValid's ndcg@1: 0.705\tValid's ndcg@3: 0.737022\tValid's ndcg@5: 0.775892\n",
      "[135]\tValid's ndcg@1: 0.71\tValid's ndcg@3: 0.738159\tValid's ndcg@5: 0.778124\n",
      "[140]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.74323\tValid's ndcg@5: 0.779944\n",
      "[145]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.740577\tValid's ndcg@5: 0.77937\n",
      "[150]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.74359\tValid's ndcg@5: 0.778318\n",
      "[155]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.747475\tValid's ndcg@5: 0.778007\n",
      "[160]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.744055\tValid's ndcg@5: 0.781034\n",
      "[165]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.748246\tValid's ndcg@5: 0.7812\n",
      "[170]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.744687\tValid's ndcg@5: 0.779399\n",
      "[175]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.74392\tValid's ndcg@5: 0.781768\n",
      "[180]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.744285\tValid's ndcg@5: 0.781345\n",
      "[185]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.741981\tValid's ndcg@5: 0.783672\n",
      "[190]\tValid's ndcg@1: 0.72\tValid's ndcg@3: 0.741886\tValid's ndcg@5: 0.783423\n",
      "[195]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.742593\tValid's ndcg@5: 0.783718\n",
      "[200]\tValid's ndcg@1: 0.71\tValid's ndcg@3: 0.740903\tValid's ndcg@5: 0.780676\n",
      "[205]\tValid's ndcg@1: 0.705\tValid's ndcg@3: 0.738733\tValid's ndcg@5: 0.779162\n",
      "[210]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.737715\tValid's ndcg@5: 0.776376\n",
      "[215]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.737254\tValid's ndcg@5: 0.777398\n",
      "[220]\tValid's ndcg@1: 0.705\tValid's ndcg@3: 0.740466\tValid's ndcg@5: 0.778499\n",
      "[225]\tValid's ndcg@1: 0.7\tValid's ndcg@3: 0.739487\tValid's ndcg@5: 0.775192\n",
      "[230]\tValid's ndcg@1: 0.71\tValid's ndcg@3: 0.742717\tValid's ndcg@5: 0.777665\n",
      "[235]\tValid's ndcg@1: 0.705\tValid's ndcg@3: 0.741179\tValid's ndcg@5: 0.776118\n",
      "[240]\tValid's ndcg@1: 0.715\tValid's ndcg@3: 0.745536\tValid's ndcg@5: 0.782412\n",
      "Early stopping, best iteration is:\n",
      "[142]\tValid's ndcg@1: 0.725\tValid's ndcg@3: 0.74175\tValid's ndcg@5: 0.78148\n",
      "Best iteration: 142\n"
     ]
    }
   ],
   "source": [
    "# Train the model using LambdaRank objective\n",
    "params = {\n",
    "    'objective': 'lambdarank',  # Listwise ranking\n",
    "    # 'metric': 'auc',  # Evaluation metric for ranking\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_eval_at': [1, 3, 5],  # NDCG evaluation at different ranks\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.03, #0.2\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 21,\n",
    "    # 'scale_pos_weight': 3.0\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_set=train_data,\n",
    "    valid_sets=[val_data],\n",
    "    valid_names=['Valid'],\n",
    "    num_boost_round=500,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100), \n",
    "        lgb.log_evaluation(5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# After training, the best iteration (round) can be accessed\n",
    "best_iteration = model.best_iteration\n",
    "print(f\"Best iteration: {best_iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "129f1652-1b01-4cd4-be08-5c7dd0859078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7698748716742498\n"
     ]
    }
   ],
   "source": [
    "# Predict scores for test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "test_scores = model.predict(testdf[feature_columns], num_iteration=best_iteration)\n",
    "\n",
    "auc = roc_auc_score(testdf['labels'], test_scores)\n",
    "print(f\"AUC: {auc}\")\n",
    "\n",
    "# Add scores to test dataframe and sort sentences within each group\n",
    "testdf['score'] = test_scores\n",
    "testdf = testdf.sort_values(by=['reviewid', 'score'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc8833ef-2531-4267-92cf-450ca8f063b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_probabilities(scores):\n",
    "    return 1 / (1 + np.exp(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "117b03ae-2117-4de1-ad45-ca3910f5ffd1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Calculating accuracy\n",
    "predictions = []\n",
    "truths = []\n",
    "threshold=0.7\n",
    "for i in range(100):\n",
    "    probabs = get_probabilities(np.array(testdf[testdf['reviewid']==i]['score']))\n",
    "    truths.extend(testdf[testdf['reviewid']==i]['labels'].tolist())\n",
    "    preds = [1 if p>threshold else 0 for p in probabs]\n",
    "    predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51eff280-35bc-4f6e-86a2-cacecf3983d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8315151515151515"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cf0daff-dc58-47ff-92f1-e5b42a36ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['reviewid', 'sentences', 'positions', 'score', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03b2c04a-10b3-4933-bf4b-fc4563ce2a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewid</th>\n",
       "      <th>sentences</th>\n",
       "      <th>positions</th>\n",
       "      <th>score</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>it doesn't surprise me that when the girls are...</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.738389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>No, their wives said \"fix it\" so THEY went and...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.607651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>But I think it was better not to write them if...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>-0.300231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>NGL, I was incredibly amused by it.</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.499299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>I was snickering a little at the lack of sex s...</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>-1.106418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>this was far from perfect but I still enjoyed it.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.120846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>It was a short, sweet romance with interfering...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-1.199640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    reviewid                                          sentences  positions  \\\n",
       "45         5  it doesn't surprise me that when the girls are...   0.044444   \n",
       "46         5  No, their wives said \"fix it\" so THEY went and...   0.055556   \n",
       "43         5  But I think it was better not to write them if...   0.022222   \n",
       "47         5                NGL, I was incredibly amused by it.   0.066667   \n",
       "42         5  I was snickering a little at the lack of sex s...   0.011111   \n",
       "41         5  this was far from perfect but I still enjoyed it.   0.000000   \n",
       "44         5  It was a short, sweet romance with interfering...   0.033333   \n",
       "\n",
       "       score  labels  \n",
       "45  0.738389       1  \n",
       "46  0.607651       1  \n",
       "43 -0.300231       0  \n",
       "47 -0.499299       0  \n",
       "42 -1.106418       0  \n",
       "41 -1.120846       0  \n",
       "44 -1.199640       0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[testdf['reviewid']==5][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71d9ddaa-46fe-4d80-9ecf-97f2b9e7f818",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from reviewplot import print_with_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62476e11-c5a2-4356-b765-af289797e61f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testdf = testdf.sort_values(by=['reviewid', 'positions'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b7f858e-b518-4c6b-b25c-46c7a68c28a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "probabilities = get_probabilities(np.array(testdf[testdf['reviewid']==5]['score']))\n",
    "truth = np.array(testdf[testdf['reviewid']==5]['labels']).astype(float)\n",
    "sentences = np.array(testdf[testdf['reviewid']==5]['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f585ff1-3b7c-407d-88df-91c7fd8b2bd6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #aedae9\">this was far from perfect but I still enjoyed it. I was snickering a little at the lack of sex scenes because, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #aedae9\">well, I've read foster before.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e2f3f3\"> But I think it was better not to write them if she couldn't write them well.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #aedae9\"> It was </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #aedae9\">a short, sweet romance with interfering family.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\"> it doesn't surprise me that when the girls are basically like </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\">\"fix </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\">this\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\">, it didn't even occur to the guys to go to Chris and say </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\">\"you can tell Matt\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fba55c\">.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\"> No, their wives said </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\">\"fix it\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\"> </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #fdda8a\">so THEY went and told Matt and invited him over to talk to Chris so they could HOVER.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e2f3f3\"> NGL, I was incredibly amused </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #e2f3f3\">by it.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;0;0;0;48;2;174;218;233mthis was far from perfect but I still enjoyed it.\u001b[0m\u001b[38;2;0;0;0;48;2;174;218;233m I was snickering a little at the lack of sex scenes because, \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;174;218;233mwell, I've read foster before.\u001b[0m\u001b[38;2;0;0;0;48;2;226;243;243m But I think it was better not to write them if she couldn't write them well.\u001b[0m\u001b[38;2;0;0;0;48;2;174;218;233m It was \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;174;218;233ma short, sweet romance with interfering family.\u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m it doesn't surprise me that when the girls are basically like \u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m\"fix \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;251;165;92mthis\"\u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m, it didn't even occur to the guys to go to Chris and say \u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m\"you can tell Matt\"\u001b[0m\u001b[38;2;0;0;0;48;2;251;165;92m.\u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m No, their wives said \u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m\"fix it\"\u001b[0m\u001b[38;2;0;0;0;48;2;253;218;138m \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;253;218;138mso THEY went and told Matt and invited him over to talk to Chris so they could HOVER.\u001b[0m\u001b[38;2;0;0;0;48;2;226;243;243m NGL, I was incredibly amused \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;226;243;243mby it.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_with_probs(sentences, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5950543f-5aaf-4f09-bf61-fd17c7b3993d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">this was far from perfect but I still enjoyed it. I was snickering a little at the lack of sex scenes because, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">well, I've read foster before. But I think it was better not to write them if she couldn't write them well. It was </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">a short, sweet romance with interfering family.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\"> it doesn't surprise me that when the girls are basically like </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">\"fix </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">this\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">, it didn't even occur to the guys to go to Chris and say </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">\"you can tell Matt\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">. No, their wives said </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">\"fix it\"</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\"> </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #cc2526\">so THEY went and told Matt and invited him over to talk to Chris so they could HOVER.</span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\"> NGL, I was incredibly amused </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #4576b4\">by it.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;0;0;0;48;2;69;118;180mthis was far from perfect but I still enjoyed it.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m I was snickering a little at the lack of sex scenes because, \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;69;118;180mwell, I've read foster before.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m But I think it was better not to write them if she couldn't write them well.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m It was \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;69;118;180ma short, sweet romance with interfering family.\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m it doesn't surprise me that when the girls are basically like \u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m\"fix \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;204;37;38mthis\"\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m, it didn't even occur to the guys to go to Chris and say \u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m\"you can tell Matt\"\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m.\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m No, their wives said \u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m\"fix it\"\u001b[0m\u001b[38;2;0;0;0;48;2;204;37;38m \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;204;37;38mso THEY went and told Matt and invited him over to talk to Chris so they could HOVER.\u001b[0m\u001b[38;2;0;0;0;48;2;69;118;180m NGL, I was incredibly amused \u001b[0m\n",
       "\u001b[38;2;0;0;0;48;2;69;118;180mby it.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_with_probs(sentences, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bfca0b99-da75-4858-a81a-073432a37a0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>contexts</th>\n",
       "      <th>labels</th>\n",
       "      <th>positions</th>\n",
       "      <th>reviewid</th>\n",
       "      <th>bookid</th>\n",
       "      <th>item_spec_score_max</th>\n",
       "      <th>item_spec_score_mean</th>\n",
       "      <th>tfidfscore</th>\n",
       "      <th>combined_embedding</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a fun series.</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.013789</td>\n",
       "      <td>0.785133</td>\n",
       "      <td>[0.13568804, -0.42419568, 0.22611226, 0.193501...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435559</td>\n",
       "      <td>-0.028487</td>\n",
       "      <td>0.224099</td>\n",
       "      <td>0.136431</td>\n",
       "      <td>0.306240</td>\n",
       "      <td>0.047697</td>\n",
       "      <td>0.344808</td>\n",
       "      <td>0.247321</td>\n",
       "      <td>0.494328</td>\n",
       "      <td>-0.217180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved Wool, and Dust and Shift both gave us ...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.027685</td>\n",
       "      <td>0.417833</td>\n",
       "      <td>[0.27358928, 0.051419273, 0.13299458, 0.160809...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.457130</td>\n",
       "      <td>-0.071240</td>\n",
       "      <td>0.153160</td>\n",
       "      <td>-0.042372</td>\n",
       "      <td>0.042692</td>\n",
       "      <td>0.019526</td>\n",
       "      <td>0.195423</td>\n",
       "      <td>0.173676</td>\n",
       "      <td>0.141578</td>\n",
       "      <td>-0.039212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think the first book was by far the best, bu...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>0.484192</td>\n",
       "      <td>[-0.07830019, -0.3241384, 0.26186368, -0.03014...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182080</td>\n",
       "      <td>0.103592</td>\n",
       "      <td>0.182030</td>\n",
       "      <td>0.297668</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>0.086083</td>\n",
       "      <td>-0.020139</td>\n",
       "      <td>0.024291</td>\n",
       "      <td>-0.069403</td>\n",
       "      <td>-0.231655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was the conclusion we wanted to see - the p...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.036474</td>\n",
       "      <td>0.021774</td>\n",
       "      <td>0.535509</td>\n",
       "      <td>[0.2418055, -0.1830729, 0.39519662, -0.0359889...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044703</td>\n",
       "      <td>-0.406086</td>\n",
       "      <td>0.235105</td>\n",
       "      <td>-0.193855</td>\n",
       "      <td>0.113906</td>\n",
       "      <td>-0.282803</td>\n",
       "      <td>0.419765</td>\n",
       "      <td>0.222623</td>\n",
       "      <td>-0.139149</td>\n",
       "      <td>-0.090754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My problem with this book is there were lots o...</td>\n",
       "      <td>Dust</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0</td>\n",
       "      <td>17855756</td>\n",
       "      <td>0.036625</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>0.653747</td>\n",
       "      <td>[0.096865825, 0.07542943, 0.061335944, 0.11228...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320965</td>\n",
       "      <td>-0.098903</td>\n",
       "      <td>0.168757</td>\n",
       "      <td>0.058654</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>-0.019319</td>\n",
       "      <td>-0.196473</td>\n",
       "      <td>0.120615</td>\n",
       "      <td>-0.143962</td>\n",
       "      <td>0.279851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14290</th>\n",
       "      <td>Will read the next.</td>\n",
       "      <td>Forever Odd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>698</td>\n",
       "      <td>16433</td>\n",
       "      <td>0.177566</td>\n",
       "      <td>0.144543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.10743135, -0.3015935, 0.03974713, 0.0797066...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358973</td>\n",
       "      <td>-0.126794</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.094335</td>\n",
       "      <td>0.336781</td>\n",
       "      <td>0.012558</td>\n",
       "      <td>-0.012272</td>\n",
       "      <td>0.594620</td>\n",
       "      <td>-0.238397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14291</th>\n",
       "      <td>If I only had one word to sum it up then \"odd\".</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.122285</td>\n",
       "      <td>0.631535</td>\n",
       "      <td>[0.12413848, 0.19855367, 0.042200167, 0.019212...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060622</td>\n",
       "      <td>-0.015157</td>\n",
       "      <td>-0.239266</td>\n",
       "      <td>-0.518556</td>\n",
       "      <td>0.096743</td>\n",
       "      <td>-0.104593</td>\n",
       "      <td>0.085093</td>\n",
       "      <td>0.047637</td>\n",
       "      <td>0.067509</td>\n",
       "      <td>0.148426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>It did keep swapping from first to third perso...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.143460</td>\n",
       "      <td>0.104940</td>\n",
       "      <td>0.356158</td>\n",
       "      <td>[-0.15070404, 0.08648281, 0.079170436, 0.15373...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363667</td>\n",
       "      <td>0.361313</td>\n",
       "      <td>-0.013605</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>-0.074386</td>\n",
       "      <td>0.271997</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>0.021483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>Some dark things happen which kind of just get...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>0.086142</td>\n",
       "      <td>0.528640</td>\n",
       "      <td>[0.5452099, 0.20342357, 0.3213288, 0.1988398, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199145</td>\n",
       "      <td>-0.415404</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>-0.126928</td>\n",
       "      <td>0.120654</td>\n",
       "      <td>0.226310</td>\n",
       "      <td>0.314678</td>\n",
       "      <td>0.093227</td>\n",
       "      <td>-0.403474</td>\n",
       "      <td>0.314984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>Really odd, and the twist at the end, a little...</td>\n",
       "      <td>The Lace Reader</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>699</td>\n",
       "      <td>1951125</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.116832</td>\n",
       "      <td>0.530047</td>\n",
       "      <td>[-0.10798588, -0.28911787, 0.14432462, 0.18672...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053777</td>\n",
       "      <td>-0.305939</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.384679</td>\n",
       "      <td>0.347311</td>\n",
       "      <td>-0.136916</td>\n",
       "      <td>-0.066333</td>\n",
       "      <td>-0.024981</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>-0.263914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14295 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences         contexts  \\\n",
       "0                                     What a fun series.             Dust   \n",
       "1      I loved Wool, and Dust and Shift both gave us ...             Dust   \n",
       "2      I think the first book was by far the best, bu...             Dust   \n",
       "3      It was the conclusion we wanted to see - the p...             Dust   \n",
       "4      My problem with this book is there were lots o...             Dust   \n",
       "...                                                  ...              ...   \n",
       "14290                                Will read the next.      Forever Odd   \n",
       "14291    If I only had one word to sum it up then \"odd\".  The Lace Reader   \n",
       "14292  It did keep swapping from first to third perso...  The Lace Reader   \n",
       "14293  Some dark things happen which kind of just get...  The Lace Reader   \n",
       "14294  Really odd, and the twist at the end, a little...  The Lace Reader   \n",
       "\n",
       "       labels  positions  reviewid    bookid  item_spec_score_max  \\\n",
       "0           0   0.000000         0  17855756             0.015290   \n",
       "1           0   0.007143         0  17855756             0.050604   \n",
       "2           0   0.014286         0  17855756             0.050604   \n",
       "3           1   0.021429         0  17855756             0.036474   \n",
       "4           1   0.028571         0  17855756             0.036625   \n",
       "...       ...        ...       ...       ...                  ...   \n",
       "14290       0   0.021429       698     16433             0.177566   \n",
       "14291       0   0.000000       699   1951125             0.215878   \n",
       "14292       1   0.007143       699   1951125             0.143460   \n",
       "14293       0   0.014286       699   1951125             0.119985   \n",
       "14294       0   0.021429       699   1951125             0.215878   \n",
       "\n",
       "       item_spec_score_mean  tfidfscore  \\\n",
       "0                  0.013789    0.785133   \n",
       "1                  0.027685    0.417833   \n",
       "2                  0.026657    0.484192   \n",
       "3                  0.021774    0.535509   \n",
       "4                  0.024668    0.653747   \n",
       "...                     ...         ...   \n",
       "14290              0.144543    1.000000   \n",
       "14291              0.122285    0.631535   \n",
       "14292              0.104940    0.356158   \n",
       "14293              0.086142    0.528640   \n",
       "14294              0.116832    0.530047   \n",
       "\n",
       "                                      combined_embedding  ...       118  \\\n",
       "0      [0.13568804, -0.42419568, 0.22611226, 0.193501...  ... -0.435559   \n",
       "1      [0.27358928, 0.051419273, 0.13299458, 0.160809...  ... -0.457130   \n",
       "2      [-0.07830019, -0.3241384, 0.26186368, -0.03014...  ... -0.182080   \n",
       "3      [0.2418055, -0.1830729, 0.39519662, -0.0359889...  ... -0.044703   \n",
       "4      [0.096865825, 0.07542943, 0.061335944, 0.11228...  ...  0.320965   \n",
       "...                                                  ...  ...       ...   \n",
       "14290  [0.10743135, -0.3015935, 0.03974713, 0.0797066...  ...  0.358973   \n",
       "14291  [0.12413848, 0.19855367, 0.042200167, 0.019212...  ... -0.060622   \n",
       "14292  [-0.15070404, 0.08648281, 0.079170436, 0.15373...  ... -0.363667   \n",
       "14293  [0.5452099, 0.20342357, 0.3213288, 0.1988398, ...  ... -0.199145   \n",
       "14294  [-0.10798588, -0.28911787, 0.14432462, 0.18672...  ...  0.053777   \n",
       "\n",
       "            119       120       121       122       123       124       125  \\\n",
       "0     -0.028487  0.224099  0.136431  0.306240  0.047697  0.344808  0.247321   \n",
       "1     -0.071240  0.153160 -0.042372  0.042692  0.019526  0.195423  0.173676   \n",
       "2      0.103592  0.182030  0.297668 -0.002652  0.086083 -0.020139  0.024291   \n",
       "3     -0.406086  0.235105 -0.193855  0.113906 -0.282803  0.419765  0.222623   \n",
       "4     -0.098903  0.168757  0.058654  0.006225 -0.019319 -0.196473  0.120615   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14290 -0.126794  0.024562  0.004872  0.094335  0.336781  0.012558 -0.012272   \n",
       "14291 -0.015157 -0.239266 -0.518556  0.096743 -0.104593  0.085093  0.047637   \n",
       "14292  0.361313 -0.013605  0.017482  0.059031  0.003847 -0.074386  0.271997   \n",
       "14293 -0.415404  0.013450 -0.126928  0.120654  0.226310  0.314678  0.093227   \n",
       "14294 -0.305939 -0.016809 -0.384679  0.347311 -0.136916 -0.066333 -0.024981   \n",
       "\n",
       "            126       127  \n",
       "0      0.494328 -0.217180  \n",
       "1      0.141578 -0.039212  \n",
       "2     -0.069403 -0.231655  \n",
       "3     -0.139149 -0.090754  \n",
       "4     -0.143962  0.279851  \n",
       "...         ...       ...  \n",
       "14290  0.594620 -0.238397  \n",
       "14291  0.067509  0.148426  \n",
       "14292 -0.012426  0.021483  \n",
       "14293 -0.403474  0.314984  \n",
       "14294  0.198668 -0.263914  \n",
       "\n",
       "[14295 rows x 138 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fac3768d-a199-4dc0-9369-7b12fac51868",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_csv('train.csv', index=False)\n",
    "valdf.to_csv('valid.csv', index=False)\n",
    "testdf.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a902bee-a42d-40ba-a56a-a264bbf7a45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
